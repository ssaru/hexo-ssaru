---
title: Kubernetes 소개
date: 2020-01-13 00:57:30
tags: [Cloud, Kubernetes]
categories: [Develop, Cloud]
keywords:
- Kubernetes
- Cloud
- Container Orchestration
coverImage: cover.jpeg
thumbnailImagePosition: left
thumbnailImage: cover.jpeg
autoThumbnailImage: yes
photos: https://images.unsplash.com/photo-1553792012-5c75e251255e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1950&q=80
---

이번 포스팅은 Kubernetes가 무엇이고 왜 필요한지에 대해 소개합니다.

<!-- excerpt -->



<!--toc-->

# Kubernetes란?

Kubernetes는 구글이 [15년에 걸친 대규모 상용 워크로드 운영 경험](https://dl.acm.org/doi/pdf/10.1145/2898442.2898444?download=true&fbclid=IwAR3c67506xGJe9-QDTNT0CtmWQxHhIjrruLQdIt-gUkIh77WvJs-mVatFSk)을 기반으로 만들어졌으며 2014년에 오픈소스화된 컨테이너 오케스트레이션 도구이다.



## Why Kubernetes?

왜 Kubernetes가 그렇게 인기가 많을까? 

이는 과거 어플리케이션을 개발하고 배포하는 방식이 어떻게 발전해왔는지를 살펴보면 Kubernetes의 인기가 많은지에 대한 도움이 되지 않을까 싶다.

![](https://d33wubrfki0l68.cloudfront.net/26a177ede4d7b032362289c6fccd448fc4a91174/eb693/images/docs/container_evolution.svg)

### 전통적인 어플리케이션 배포

과거에는 어플리케이션(예를 들어 웹 어플리케이션)을 개발하게 되면 하나의 물리 서버에 웹 어플리케이션을 구축하고 배포해서 사용했다. 만약에 여러 어플리케이션을 개발하게 되어 배포하는 경우에는 여러 대의 물리 서버를 구축하여 배포하는 방식을 사용했다.

이는 하나의 물리 서버에 여러 개의 어플케이션을 배포하는 경우 리소스, 의존성 패키지, 어플리케이션 셋팅 등으로 인하여 하나의 어플리케이션이 다른 어플리케이션에 영향을 주었기 때문이다.



### 가상 OS를 이용한 배포

전통적인 어플리케이션 배포의 단점을 극복하기 위해서 가상 OS(Virtual Machine)을 이용하여 여러 어플리케이션을 배포하는 방법이 도입되었다. 

가상 OS는 물리 서버 위에 호스트 OS가 설치되고 그 위에 다시 게스트 OS가 설치되어 운영되는 방식으로 격리된 OS환경으로, 물리 서버에서 직접 리소스를 사용하는 것 보다 효율적으로 리소스를 사용할 수 있고, 쉽게 어플리케이션을 추가하거나 삭제할 수 있으며, 쉽게 확장할 수 있다는 장점이 있다. 

다만 하이퍼 바이저와 호스트 OS위에 설치되는 게스트 OS설치로 인해 불필요한 중복이 발생되어 물리 서버의 호스트 OS에 비해서 성능이 하락한다는 단점이 있다.



### 컨테이너를 활용한 배포

Docker라는 컨테이너 기술이 유명해짐과 동시에 컨테이너 기술을 사용하여 어플리케이션을 배포하는 방법이 도입되었다. 

컨테이너는 가상 OS와는 다르게 리눅스 커널의 컨테이너 기술을 활용하여 호스트 OS를 공유하는 기술이다. 

가상 OS와 비교했을 때 상대적으로 성능 하락이 적다는 것이 장점이며 기존 가상 OS의 장점들(격리 환경, 확장성 등등)은 유지된다는 장점이 있다.



### Kubernetes

컨테이너 기술을 활용한 배포 방식이 도입되었지만, 기존 Docker나 Docker Compose와 같은 기술은 대규모 컨컨테이너를 다루지 않았고, 더 나아가 대규모 컨테이너를 이기종 분산 클러스터 환경에서 이를 통합하여 관리하는 기술 또한 없었다. 

Kubernetes는 분산 클러스터 환경에서 컨테이너를 관리할 수 있는 컨테이너 오케스트레이션 도구라고 할 수 있다.

 Kubernetes는 분산 클러스터 환경에서 컨테이너를 관리하는 것 뿐만 아니라 로드 밸린싱과 오토 스케일을 이용하여 트래픽이 과도한 어플리케이션의 컨테이너를 다수로 복제하여 트래픽을 분산시킬 수 있는 기능, 컨테이너에 장애가 생겼을 때 이를 복구해주는 장애 처리 기능, 배포 시 배포 안정성을 위한 Blue-Green 배포, 카나리 배포, 롤링 배포 등의 고 가용성 기능들도 함께 제공한다.

<br/>

## 역사

Kubernetes에 대한 설명을 시작하기 전에 개인적으로 Kubernetes가 어떻게 개발되게 되었는지 역사를 살펴보게 되면 Kubernetes를 이해하는데 도움이 된다고 생각한다. 

구글은 과거부터 지금까지 Borg, Omega, Kubernetes 순으로 세 가지의 리눅스 컨테이너 관리 시스템을 만들었는데, 이에 대해 간단하게 소개한다.



#### Borg

Borg의 개발은 구글 내부에서 개별적으로 두 개의 시스템으로 동작 했던 장기 실행 서비스(Long-running services)와 배치 작업(batch jobs)를 모두 관리하자는 차원에서 시작되었다. Borg는 두 가지 시스템을 통합해서 리소스 활용도를 높이고 비용을 줄이려 하였다.

Borg는 다양한 어플리케이션들이 시스템을 공유하는 것이 특징이다. 이는 리눅스 커널이 컨테이너 시스템을 지원하기 때문에 가능한 것이었고, 덕분에 하나의 시스템 안에서 지연 시간에 민감한 서비스와 CPU 사용량이 많은 일괄 처리 프로세스를 격리할 수 있었다.

Borg는 작업을 업데이트와 설정 방법에 대한 여러 메카니즘을 제공했는데, 그 메카니즘은 아래와 같다.

1. 리소스 사용량 예측
2. 서비스 디스커버리와 로드 밸런싱
3. 할당량 관리(quota management)
4. 기타

Borg로 인해 구글 내의 많은 어플리케이션이 Borg에서 작동될 수 있도록 개발되기 시작했고 구글 어플리케이션 팀과 인프라팀은 Borg를 위한 많은 도구와 서비스들을 개발했다. 

하지만 생태계 구축이 구글 내부에서 필요에 따라 개발되다 보니 이기종 시스템에서 서로 다른 언어와 프로세스를 이용하여 임시 시스템의 모음들이 만들어지게 되었다. 

*(개인적인 생각으로는 필요에 따라서 Borg에 필요한 기능을 추가하다보니 도구와 시스템의 파편화가 많이 발생하지 않았을까 싶다.)*

하지만 결국 기존에 Borg를 사용하고 있는 시스템의 규모, 폭 넓은 기능, 강인함이라는 특성으로 구글의 컨테이너 기본 매니저로 남아있게 된다.



#### Omega

Omega는 Borg의 후속 프로젝트로 Borg의 생태계를 개선하려는 것에서 출발하였다. 따라서 Borg에서 성공적이었던 패턴을 적용함과 동시에 일관성있는 아키텍쳐 기반으로 설계되고 구현되었다. 

*(앞서 이야기했듯이 Borg의 파편화, 필요에 따른 추가 기능, 아키텍쳐의 불완전함으로 Omega프로젝트가 시작되었다고 생각한다.)*

예를 들어 Omega는 때때로 발생하는 충돌을 해결하기 위해서 클러스터의 상태를 중앙화된 Paxos 기반의 트랜젝션 지향 저장소에 저장했다. 저장 작업은 다른 클러스터의 컨트롤 플레인(스켸쥴러)에 의해서 실행되었다. 

Omega의 이런 디커플링은 Borg Master의 기능을 단일 시스템에서 수행하는 것이 아니라 피어 역활을 하는 별도의 구성 요소로 분리할 수 있게 했다. 

추후 Omega에서 개발된 많은 기능들을 Borg 내부로 흡수되었다.

*예전에는 모든 기능을 Master Node에서 관리하고 작업했다면 그 기능을 세분화하여 각각 핵심 역활을하는 Node를 분산하여 처리했다는 이야기로 들린다. 이는 특정 Node에 장애가 발생하여 특정 역활을 하는 Node가 제 역활을 하지 못하더라도 다른 역활을하는 Node는 정상적으로 작동하기 때문에 장애 전파가 발생하지 않는다는 것을 의미한다.*



#### Kubernetes

Kubernetes는 구글이 선보인 세번째 컨테이너 관리 도구로 Kubernetes는 구글이 내부적으로 운용하고 개발했던 Borg과 Omega 프로젝트를 기반으로 하여 개발되었으며 Borg와 Omega프로젝트를 통한 경험들과 노하우들로 개발되어 Borg와 Omega에서 지원하는 많은 기능들을 제공한다.

Kubernetes의 개발 목적은 외부 개발자들에게 리눅스 컨테이너에 조금 더 관심 갖게 만드는 것과 GCP(Google Cloud Platform)을 더 성장시킬 목적으로 개발되었으며 오픈소스로 공개되었다.

# Kubernetes Component

Kubernetes는 기본적으로 여러 대의 물리 서버가 네트워크 기반으로 엮여있는 환경에 설치하게 되며 분산 클러스터 환경을 만들어 준다. 클러스터는 최소 1개의 워커 노드와 최소 1개의 마스터 노드를 갖는다. *(Minikube를 사용할 경우 물리 서버 1대에서 Kubernetes를 사용해볼 수 있다.)*

Kubernetes의 워커 노드는 어플리케이션 구성요소인 파드를 호스트한다. 여기서 파드란 Kubernetes의 제일 기본 요소로 하나 이상의 실행 중인 컨테이너로 구성된다. 워커 노드와 클러스터 내부에 있는 마스터는 마스터 노드가 관리하게 되며, Kubernetes에서는 파드를 관리하는 마스터 노드의 장애극복과 고가용성 클러스터 구축을 위해 마스터 노드를 여러대로 설정할 수 있는 기능을 지원한다.

Kubernetes의 클러스터 다이어그램은 아래 그림과 같으며 주 컴포넌트는 다음과 같다.

- Master 
  - kube-apiserver
  - etcd
  - kube-scheduler
  - kube-controller-manager
  - cloud-controller-manager
- Node 
  - kubelet
  - kube-proxy
  - container runtime

![https://d33wubrfki0l68.cloudfront.net/817bfdd83a524fed7342e77a26df18c87266b8f4/3da7c/images/docs/components-of-kubernetes.png](https://d33wubrfki0l68.cloudfront.net/817bfdd83a524fed7342e77a26df18c87266b8f4/3da7c/images/docs/components-of-kubernetes.png)

## Master

마스터는 클러스터에 관한 전반적인 결정을 수행하고 클러스터 이벤트를 감지하고 반응한다. *(예를 들어 파드가 비정상 종료했을 때, 이를 감지해서 재시동을 하는 것 등)*

마스터는 클러스터 내 어떠한 머신에서 동작할 수 있다. 하지만 간결성을 위해서 Kubernetes를 설치하는 스크립트는 해당 스크립트를 실행한 호스트 머신을 마스터로 구동시킨다. 마스터로 구성된 머신은 사용자 컨테이너를 동작시키지 않는다.

### kube-apiserver

API 서버는 Kubernetes API를 노출하는 컨트롤 플레인 컴포넌트이다. API 서버는 Kubernetes 컨트롤 플레인의 프론트 엔드이다.

kube-apiserver는 수평으로 확장되도록 디자인 되어, 여러 kube-apiserver 인스턴스를 배포해서 확장할 수 있다.

### etcd

모든 클러스터 데이터를 저장하는 일관성, 고가용성 키-값 저장소이다.

etcd의 데이터는 kubernetes 클러스터의 데이터를 저장하고 있으므로 데이터의 백업 계획은 필수이다.

### kube-scheduler

새로 생성되어 노드가 배정되지 않은파드를 감지하고 구동될 노드를 선택하는 컴포넌트.

마스터 상에서 작동하고 있으며, 스케줄링 작업을 위해서 고려되는 요소는 리소스에 대한 개별 및 총체적 요구사항 ,하드웨어/소프트웨어/정책적 제약, 어피니티 및 안티-어피니티 명세, 데이터 지역성, 워크로드 간 간섭, 데드라인 등을 포함한다.

### kube-controller-manager

컨트롤러를 구동하는 마스터 상의 컴포넌트들로 여러 종류가 있다.

1. 노드 컨트롤러 
   - 노드에 장애가 생겼을 때, 그에 대한 알람과 대응에 대한 역활을 한다.
2. 레플리케이션 컨트롤러 
   - 시스템이 요구하는 파드의 복제본 수들을 알맞게 유지시켜준다.
3. 엔드포인트 컨트롤러 
   - 서비스와 파드를 연결한다.
4. 서비스 어카운트 & 토큰 컨트롤러 
   - 네임스페이스에 대한 기본 계정과 API 접근 토근을 생성한다.

논리적으로 각 컨트롤러는 개별 프로세스이지만, 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다.

### cloud-controller-manager

클라우드 제공사업자와 상호작용하는 컨트롤러

## Node

노드 컴포넌트는 동작 중인 파드를 유지시키고 쿠버네티스 런타임 환경을 제공하며, 모든 노드 상에서 동작한다. 노드 컴포넌트는 아래와 같다.

1. Kubelet
2. Kube-proxy
3. 컨테이너 런타임

### Kubelet

클러스터의 각 노드에서 실행되는 에이전트로 Kubelet은 파드에서 컨테이너가 확실하게 동작하도록 관리한다. 즉, Kubelet은 다양한 메커니즘을 통해 제공된 파드 스펙을 받아서 컨테이너가 파드 스펙에 맞춰 잘 동작할 수 있도록 보장하는 역활을 한다.

**노트**

- Kubelet은 쿠버네티스를 통해 생성되지 않은 컨테이너는 관리하지 않는다.

### Kube-proxy

kube-proxy는 클러스터의 각 노드에서 실행되는 네트워크 프록시이며, 쿠버네티스ㅇ의 서비스 개념의 구현체다.

kube-proxy의 역활은 노드의 네트워크 규칙을 유지/관리하는 것이다. 유지,관리되는 네트워크 규칙을 통해서 내부 네트워크 세션이나 클러스터 바깥에서 파드로 네트워크 통신을 가능할 수 있도록 해준다.

Kube-proxy는 운영 체제에 가용한 패킷 필터링 계층이 있는 경우, 이를 그대로 사용한다. 만약 없다면 Kube-proxy는 트래픽 자체를 포워드(forward)한다.

### Container Runtime

컨테이너 실행을 담당하는 소프트웨어이다.

쿠버네티스는 여러 컨테이너를 지원하는데, 대표적인 종류로는 아래와 같다.

1. Docker
2. Containerd
3. cri-o
4. rktlet
5. 그 밖에 Kubernetes CRI를 구현한 모든 소프트웨어

# Add On

애드온은 쿠버네티스 리소스(데몬셋, 디플로이먼트 등)을 이용해서 클러스터 기능을 구현한다. 클러스터 단위의 기능을 제공하기 때문에 애드온에 대한 네임스페이스 리소스는 *kube-system*에 속한다.

## DNS

대게 많은 예제에서 DNS기능을 요구하기 때문에 모든 쿠버네티스 클러스터는 클러스터 DNS를 갖추어야 한다. 클러스터 DNS는 구성환경 내 다른 DNS서버와 더불어, 쿠버네티스 서비스를 위해 DNS 레코드를 제공해주는 DNS 서버이다.

쿠버네티스에 의해 구동되는 컨테이너는 DNS 검색에서 해당 DNS 서버를 자동으로 포함한다.

## 웹UI(대시보드)

대시보드는 쿠버네티스 클러스터를 위한 범용의 웹기반 UI이다. 사용자가 클러스터 자체뿐만 아니라, 클러스터에서 동작하는 어플리케이션에 대한 관리와 고장처리를 할 수 있도록 허용해준다.

## 컨테이너 리소스 모니터링

컨테이너 리소스 모니터링은 중앙 데이터베이스 내에 컨테이너에 대한 시계열 매트릭스를 기록하고 그 데이터를 열람하기 위한 UI를 제공해준다.

## 클러스터 레벨 로깅

중앙 로그 저장소에 컨테이너 로그를 저장하는 역활을 한다.



# Reference

1. [쿠버네티스란 무엇인가?](https://kubernetes.io/ko/docs/concepts/overview/what-is-kubernetes/)
2. [Borg, Omega, and Kubernetes](https://dl.acm.org/doi/pdf/10.1145/2898442.2898444?download=true&fbclid=IwAR3c67506xGJe9-QDTNT0CtmWQxHhIjrruLQdIt-gUkIh77WvJs-mVatFSk)

